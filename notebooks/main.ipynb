{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de01b72a-8cb9-4b11-bcfb-5a51a18ff0e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-30T05:12:59.486267Z",
     "iopub.status.busy": "2023-04-30T05:12:59.485668Z",
     "iopub.status.idle": "2023-04-30T05:12:59.491400Z",
     "shell.execute_reply": "2023-04-30T05:12:59.490766Z",
     "shell.execute_reply.started": "2023-04-30T05:12:59.486229Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/work/NewsTitles\r\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ae28f28-23e0-4e59-bf37-f14117da9287",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T05:15:51.663078Z",
     "iopub.status.busy": "2023-04-27T05:15:51.662392Z",
     "iopub.status.idle": "2023-04-27T05:15:56.342731Z",
     "shell.execute_reply": "2023-04-27T05:15:56.341118Z",
     "shell.execute_reply.started": "2023-04-27T05:15:51.663033Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.9/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5)\r\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import paddle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import paddlenlp\n",
    "import paddle.nn.functional as F \n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "from paddle.io import Dataset, DataLoader\n",
    "from paddlenlp.transformers import BertTokenizer, AutoModelForSequenceClassification, AutoTokenizer, AutoModel\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69836213-cc09-4200-926c-b75b7542e2f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T05:15:56.345192Z",
     "iopub.status.busy": "2023-04-27T05:15:56.344197Z",
     "iopub.status.idle": "2023-04-27T05:15:56.355846Z",
     "shell.execute_reply": "2023-04-27T05:15:56.354472Z",
     "shell.execute_reply.started": "2023-04-27T05:15:56.345148Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 定义一些宏观变量\n",
    "\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 5e-5\n",
    "MODEL_NAME = \"hfl/rbt4\"\n",
    "SAVE_PATH = './' + MODEL_NAME.split('/')[-1]\n",
    "BATCH_SIZE = 1024\n",
    "SAVE_FREQUENCE = 100\n",
    "LOG_FREQUENCE = 20\n",
    "TOTAL_SIZE = 83599\n",
    "TEST_LEN1 = (TOTAL_SIZE//BATCH_SIZE)*BATCH_SIZE\n",
    "TEST_SIZE = 0.10\n",
    "RANDOM_STATE = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7925c39e-5ead-4eed-a8a4-8e89ae55b5d5",
   "metadata": {},
   "source": [
    "## 数据统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d7b7e6c-71c3-4198-a94f-87b601984e84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T05:15:56.358068Z",
     "iopub.status.busy": "2023-04-27T05:15:56.357637Z",
     "iopub.status.idle": "2023-04-27T05:15:57.522520Z",
     "shell.execute_reply": "2023-04-27T05:15:57.521790Z",
     "shell.execute_reply.started": "2023-04-27T05:15:56.358035Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最长的文本长度: 48, 标题: 拉格利・希尔顿度假酒店Hilton MaldivesResort&amp;Spa Rangali\r\n"
     ]
    }
   ],
   "source": [
    "data_dict = defaultdict(int)\n",
    "max_len, max_len_text = -float('INF'), ''\n",
    "with open('./data/Train.txt', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        label, classify, title = line.strip('\\n').strip(' ').split('\\t')\n",
    "        data_dict[classify]+=1\n",
    "        if len(title) > max_len:\n",
    "            max_len, max_len_text = len(title), title\n",
    "\n",
    "print(f'最长的文本长度: {max_len}, 标题: {max_len_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9505f8b-f6e0-4ca4-a0e1-1f12fa8e15ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T05:15:57.524797Z",
     "iopub.status.busy": "2023-04-27T05:15:57.523637Z",
     "iopub.status.idle": "2023-04-27T05:15:57.589304Z",
     "shell.execute_reply": "2023-04-27T05:15:57.588282Z",
     "shell.execute_reply.started": "2023-04-27T05:15:57.524765Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "各个种类标题的数量:\r\n",
      "\r\n",
      "\t 财经 33389\r\n",
      "\t 彩票 6830\r\n",
      "\t 房产 18045\r\n",
      "\t 股票 138959\r\n",
      "\t 家居 29328\r\n",
      "\t 教育 37743\r\n",
      "\t 科技 146637\r\n",
      "\t 社会 45765\r\n",
      "\t 时尚 12032\r\n",
      "\t 时政 56778\r\n",
      "\t 体育 118444\r\n",
      "\t 星座 3221\r\n",
      "\t 游戏 21936\r\n",
      "\t 娱乐 83369\r\n"
     ]
    }
   ],
   "source": [
    "print('各个种类标题的数量:\\n')\n",
    "for key in data_dict.keys():\n",
    "    print('\\t', key, data_dict[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5294cfef-652f-4620-8737-cdde97c2d897",
   "metadata": {},
   "source": [
    "## 获取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13dbf646-adb5-487c-b323-af8f5b378346",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T05:15:57.591030Z",
     "iopub.status.busy": "2023-04-27T05:15:57.590708Z",
     "iopub.status.idle": "2023-04-27T05:15:59.207442Z",
     "shell.execute_reply": "2023-04-27T05:15:59.206542Z",
     "shell.execute_reply.started": "2023-04-27T05:15:57.591004Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "title_labels, classes, titles = [], [], []\n",
    "with open('./data/Train.txt', 'r') as f:\n",
    "    count, pre_class = 0, ''\n",
    "    for line in f.readlines():\n",
    "        label, classify, title = line.strip('\\n').split('\\t')\n",
    "        title_labels.append(int(label))\n",
    "        classes.append(classify)\n",
    "        titles.append(title)\n",
    "\n",
    "data = {'lable': title_labels,\n",
    "        'class': classes,\n",
    "        'title': titles}\n",
    "\n",
    "train_data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1b67835-747f-4e1a-aa36-076b376bfe0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T05:15:59.209673Z",
     "iopub.status.busy": "2023-04-27T05:15:59.208759Z",
     "iopub.status.idle": "2023-04-27T05:15:59.302726Z",
     "shell.execute_reply": "2023-04-27T05:15:59.301999Z",
     "shell.execute_reply.started": "2023-04-27T05:15:59.209644Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lable</th>\n",
       "      <th>class</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>财经</td>\n",
       "      <td>上证50ETF净申购突增</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>财经</td>\n",
       "      <td>交银施罗德保本基金将发行</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>财经</td>\n",
       "      <td>基金公司不裁员反扩军 走访名校揽人才</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>财经</td>\n",
       "      <td>基金巨亏30亿 欲打开云天系跌停自救</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>财经</td>\n",
       "      <td>基金市场周二缩量走低</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752471</th>\n",
       "      <td>13</td>\n",
       "      <td>娱乐</td>\n",
       "      <td>胡彦斌为北京个唱彩排 现场传授减肥经(组图)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752472</th>\n",
       "      <td>13</td>\n",
       "      <td>娱乐</td>\n",
       "      <td>方大同薛凯琪拒评陈冠希 称其应尊重女性(组图)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752473</th>\n",
       "      <td>13</td>\n",
       "      <td>娱乐</td>\n",
       "      <td>美国资深记者透露迈克尔-杰克逊复出无望(图)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752474</th>\n",
       "      <td>13</td>\n",
       "      <td>娱乐</td>\n",
       "      <td>组图：小野猫妮可搭上F1总冠军 秀恩爱形影不离</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752475</th>\n",
       "      <td>13</td>\n",
       "      <td>娱乐</td>\n",
       "      <td>美国吉他大师莱斯-保罗因病去世 享年94岁</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>752476 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lable class                    title\n",
       "0           0    财经             上证50ETF净申购突增\n",
       "1           0    财经             交银施罗德保本基金将发行\n",
       "2           0    财经       基金公司不裁员反扩军 走访名校揽人才\n",
       "3           0    财经       基金巨亏30亿 欲打开云天系跌停自救\n",
       "4           0    财经               基金市场周二缩量走低\n",
       "...       ...   ...                      ...\n",
       "752471     13    娱乐   胡彦斌为北京个唱彩排 现场传授减肥经(组图)\n",
       "752472     13    娱乐  方大同薛凯琪拒评陈冠希 称其应尊重女性(组图)\n",
       "752473     13    娱乐   美国资深记者透露迈克尔-杰克逊复出无望(图)\n",
       "752474     13    娱乐  组图：小野猫妮可搭上F1总冠军 秀恩爱形影不离\n",
       "752475     13    娱乐    美国吉他大师莱斯-保罗因病去世 享年94岁\n",
       "\n",
       "[752476 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45659953-b17e-4286-9584-66794ce2cc4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T05:15:59.304843Z",
     "iopub.status.busy": "2023-04-27T05:15:59.303764Z",
     "iopub.status.idle": "2023-04-27T05:15:59.410840Z",
     "shell.execute_reply": "2023-04-27T05:15:59.409917Z",
     "shell.execute_reply.started": "2023-04-27T05:15:59.304814Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_title = []\n",
    "with open('./data/Test.txt', 'r') as f:\n",
    "    count = 0\n",
    "    for line in f.readlines():\n",
    "        test_title.append(line.strip('\\n'))\n",
    "test_data = pd.DataFrame({'title': test_title})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "981acbc9-00b5-465e-8582-ab6baddddc4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T05:15:59.412802Z",
     "iopub.status.busy": "2023-04-27T05:15:59.412146Z",
     "iopub.status.idle": "2023-04-27T05:15:59.426688Z",
     "shell.execute_reply": "2023-04-27T05:15:59.426037Z",
     "shell.execute_reply.started": "2023-04-27T05:15:59.412763Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>北京君太百货璀璨秋色 满100省353020元</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>教育部：小学高年级将开始学习性知识</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>专业级单反相机 佳能7D单机售价9280元</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>星展银行起诉内地客户 银行强硬客户无奈</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>脱离中国的实际 强压人民币大幅升值只能是梦想</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83594</th>\n",
       "      <td>Razer杯DotA精英挑战赛8月震撼登场</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83595</th>\n",
       "      <td>经济数据好转吹散人民币贬值预期</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83596</th>\n",
       "      <td>抵押率抵押物双控政策 刘明康支招房产贷款</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83597</th>\n",
       "      <td>8000万像素 利图发布Aptus-II 12数码后背</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83598</th>\n",
       "      <td>教育部公布33个国家万余所正规学校名单</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83599 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             title\n",
       "0          北京君太百货璀璨秋色 满100省353020元\n",
       "1                教育部：小学高年级将开始学习性知识\n",
       "2            专业级单反相机 佳能7D单机售价9280元\n",
       "3              星展银行起诉内地客户 银行强硬客户无奈\n",
       "4           脱离中国的实际 强压人民币大幅升值只能是梦想\n",
       "...                            ...\n",
       "83594        Razer杯DotA精英挑战赛8月震撼登场\n",
       "83595              经济数据好转吹散人民币贬值预期\n",
       "83596         抵押率抵押物双控政策 刘明康支招房产贷款\n",
       "83597  8000万像素 利图发布Aptus-II 12数码后背\n",
       "83598          教育部公布33个国家万余所正规学校名单\n",
       "\n",
       "[83599 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42204917-b54b-4c97-812a-9474e01029b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T05:15:59.428578Z",
     "iopub.status.busy": "2023-04-27T05:15:59.427708Z",
     "iopub.status.idle": "2023-04-27T05:16:00.063173Z",
     "shell.execute_reply": "2023-04-27T05:16:00.061957Z",
     "shell.execute_reply.started": "2023-04-27T05:15:59.428549Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "title_with_labels = [(t, l) for t,l in zip(titles, title_labels)]\n",
    "train_titles, val_titles = train_test_split(title_with_labels, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
    "\n",
    "# 将test数据分割为两份，方便批次处理\n",
    "test_data_part_1, test_data_part_2 = test_title[:TEST_LEN1], test_title[TEST_LEN1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd46be9b-f66a-473b-999a-4d5399d2584d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T05:16:00.069345Z",
     "iopub.status.busy": "2023-04-27T05:16:00.068575Z",
     "iopub.status.idle": "2023-04-27T05:16:00.086475Z",
     "shell.execute_reply": "2023-04-27T05:16:00.085471Z",
     "shell.execute_reply.started": "2023-04-27T05:16:00.069302Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75248\r\n"
     ]
    }
   ],
   "source": [
    "print(len(val_titles))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8f5352-47b0-46f0-a5d5-74a0d0b8ba1f",
   "metadata": {},
   "source": [
    "## 构造Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c086f815-ed33-4eaf-aafd-198960225243",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T05:16:00.087863Z",
     "iopub.status.busy": "2023-04-27T05:16:00.087569Z",
     "iopub.status.idle": "2023-04-27T05:16:00.176276Z",
     "shell.execute_reply": "2023-04-27T05:16:00.172191Z",
     "shell.execute_reply.started": "2023-04-27T05:16:00.087841Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, data,  tokenizer, max_seq_length=48, isTest=False):\n",
    "        super(TextDataset, self).__init__()\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.isTest = isTest\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if  not self.isTest:\n",
    "            text, label = self.data[index][0], self.data[index][1]\n",
    "            encoded = self.tokenizer.encode(text, max_seq_len=self.max_seq_length, pad_to_max_seq_len=True)\n",
    "            input_ids, token_type_ids  = encoded['input_ids'], encoded['token_type_ids']\n",
    "            return tuple([np.array(x, dtype='int64') for x in [input_ids, token_type_ids, [label]]])\n",
    "        else:\n",
    "            title = self.data[index]\n",
    "            encoded = self.tokenizer.encode(title, max_seq_len=self.max_seq_length, pad_to_max_seq_len=True)\n",
    "            input_ids, token_type_ids  = encoded['input_ids'], encoded['token_type_ids']\n",
    "            return tuple([np.array(x, dtype='int64') for x in [input_ids, token_type_ids]])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b07f1d-4f79-4e41-a794-69c2a78d0246",
   "metadata": {},
   "source": [
    "## 数据加载器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fae7dfb3-21b7-463b-bb23-a8531c8ddde5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T05:16:00.178079Z",
     "iopub.status.busy": "2023-04-27T05:16:00.177667Z",
     "iopub.status.idle": "2023-04-27T05:16:06.299292Z",
     "shell.execute_reply": "2023-04-27T05:16:06.298614Z",
     "shell.execute_reply.started": "2023-04-27T05:16:00.178048Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-04-27 13:16:00,180] [    INFO] - We are using <class 'paddlenlp.transformers.roberta.modeling.RobertaForSequenceClassification'> to load 'hfl/rbt4'.\r\n",
      "[2023-04-27 13:16:00,187] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/hfl/rbt4/rbt4_chn_large.pdparams\r\n",
      "W0427 13:16:00.191088 19519 gpu_context.cc:244] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 11.2\r\n",
      "W0427 13:16:00.195669 19519 gpu_context.cc:272] device: 0, cuDNN Version: 8.2.\r\n",
      "[2023-04-27 13:16:06,273] [    INFO] - We are using <class 'paddlenlp.transformers.roberta.tokenizer.RobertaChineseTokenizer'> to load 'hfl/rbt4'.\r\n",
      "[2023-04-27 13:16:06,276] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/hfl/rbt4/vocab.txt\r\n",
      "[2023-04-27 13:16:06,292] [    INFO] - tokenizer config file saved in /home/aistudio/.paddlenlp/models/hfl/rbt4/tokenizer_config.json\r\n",
      "[2023-04-27 13:16:06,295] [    INFO] - Special tokens file saved in /home/aistudio/.paddlenlp/models/hfl/rbt4/special_tokens_map.json\r\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_classes=14)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "train_dataset, val_dataset = TextDataset(data=train_titles, tokenizer=tokenizer), TextDataset(data=val_titles, tokenizer=tokenizer)\n",
    "test_dataset_part1 = TextDataset(data=test_data_part_1, tokenizer=tokenizer, isTest=True)\n",
    "test_dataset_part2 = TextDataset(data=test_data_part_2, tokenizer=tokenizer, isTest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbf4977e-cab1-45d5-8d34-040ae03d4b3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T05:16:06.300956Z",
     "iopub.status.busy": "2023-04-27T05:16:06.300427Z",
     "iopub.status.idle": "2023-04-27T05:16:06.307381Z",
     "shell.execute_reply": "2023-04-27T05:16:06.306623Z",
     "shell.execute_reply.started": "2023-04-27T05:16:06.300930Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 定义采样器\n",
    "train_batch_sampler = paddle.io.BatchSampler(train_dataset,\n",
    "                                        shuffle=True,\n",
    "                                        batch_size=BATCH_SIZE,\n",
    "                                        )\n",
    "\n",
    "val_batch_sampler = paddle.io.BatchSampler(val_dataset,\n",
    "                                        shuffle=True,\n",
    "                                        batch_size=BATCH_SIZE,\n",
    "                                        )\n",
    "\n",
    "test_batch_sampler = paddle.io.BatchSampler(test_dataset_part1,\n",
    "                                            shuffle=False, \n",
    "                                            batch_size=BATCH_SIZE)\n",
    "# 定义数据加载器\n",
    "train_data_loader = paddle.io.DataLoader(dataset=train_dataset,\n",
    "                                        batch_sampler=train_batch_sampler,\n",
    "                                        return_list=True,\n",
    "                                        num_workers=4)\n",
    "val_data_loader = paddle.io.DataLoader(dataset=val_dataset,\n",
    "                                        batch_sampler=val_batch_sampler,\n",
    "                                        return_list=True,\n",
    "                                        num_workers=4)\n",
    "test_data_loader = paddle.io.DataLoader(dataset=test_dataset_part1,\n",
    "                                        batch_sampler=test_batch_sampler,\n",
    "                                        return_list=True,\n",
    "                                        num_workers=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d880ec6a-4239-45f4-bacd-5c756624d447",
   "metadata": {},
   "source": [
    "## 定义评估函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb20a0d4-1783-42a2-b458-61242b4e7264",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T05:16:06.309497Z",
     "iopub.status.busy": "2023-04-27T05:16:06.308617Z",
     "iopub.status.idle": "2023-04-27T05:16:06.317275Z",
     "shell.execute_reply": "2023-04-27T05:16:06.316490Z",
     "shell.execute_reply.started": "2023-04-27T05:16:06.309467Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(model, criterion, metric, data_loader):\n",
    "    \"\"\"\n",
    "    Given a dataset, it evals model and computes the metric.\n",
    "\n",
    "    Args:\n",
    "        model(obj:`paddle.nn.Layer`): A model to classify texts.\n",
    "        data_loader(obj:`paddle.io.DataLoader`): The dataset loader which generates batches.\n",
    "        criterion(obj:`paddle.nn.Layer`): It can compute the loss.\n",
    "        metric(obj:`paddle.metric.Metric`): The evaluation metric.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    metric.reset()\n",
    "    losses = []\n",
    "    for batch in tqdm(data_loader):\n",
    "        input_ids, token_type_ids, labels = batch\n",
    "        logits = model(input_ids, token_type_ids)\n",
    "        loss = criterion(logits, labels)\n",
    "        losses.append(loss.numpy())\n",
    "        correct = metric.compute(logits, labels)\n",
    "        metric.update(correct)\n",
    "    accu = metric.accumulate()\n",
    "    print(\"eval loss: %.5f, accu: %.7f\" % (np.mean(losses), accu))\n",
    "    model.train()\n",
    "    metric.reset()\n",
    "    return accu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6c2727-aca2-4f9d-831f-4aef06efb382",
   "metadata": {},
   "source": [
    "## 定义训练过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83885d11-c82a-4475-b6fa-976e25a0a48a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T05:16:06.319583Z",
     "iopub.status.busy": "2023-04-27T05:16:06.318419Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, Thu Apr 27 13:16:06 2023\r\n",
      "\t step:20/662, average time: 0.7307, loss: 1.388521 Batch Acc:0.649414062, Acc:0.436058408\r\n",
      "\t step:40/662, average time: 0.7155, loss: 0.753680 Batch Acc:0.772460938, Acc:0.586556784\r\n",
      "\t step:60/662, average time: 0.7104, loss: 0.573487 Batch Acc:0.829101562, Acc:0.663117956\r\n",
      "\t step:80/662, average time: 0.7082, loss: 0.417339 Batch Acc:0.875976562, Acc:0.712456597\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:19<00:00,  3.75it/s]\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss: 0.33622, accu: 0.8998379\r\n",
      "\t step:100/662, average time: 0.8986, loss: 0.387817 Batch Acc:0.879882812, Acc:0.879882812\r\n",
      "\t step:120/662, average time: 0.8664, loss: 0.376510 Batch Acc:0.894531250, Acc:0.893275670\r\n",
      "\t step:140/662, average time: 0.8436, loss: 0.298052 Batch Acc:0.916992188, Acc:0.897651486\r\n",
      "\t step:160/662, average time: 0.8263, loss: 0.308648 Batch Acc:0.907226562, Acc:0.900678791\r\n",
      "\t step:180/662, average time: 0.8129, loss: 0.268319 Batch Acc:0.918945312, Acc:0.903380594\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:20<00:00,  3.66it/s]\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss: 0.24698, accu: 0.9240246\r\n",
      "\t step:200/662, average time: 0.9007, loss: 0.306187 Batch Acc:0.907226562, Acc:0.907226562\r\n",
      "\t step:220/662, average time: 0.8830, loss: 0.237749 Batch Acc:0.926757812, Acc:0.917131696\r\n",
      "\t step:240/662, average time: 0.8683, loss: 0.294690 Batch Acc:0.914062500, Acc:0.915825076\r\n",
      "\t step:260/662, average time: 0.8560, loss: 0.221337 Batch Acc:0.939453125, Acc:0.916864114\r\n",
      "\t step:280/662, average time: 0.8453, loss: 0.229739 Batch Acc:0.927734375, Acc:0.918680073\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:20<00:00,  3.65it/s]\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss: 0.21686, accu: 0.9320646\r\n",
      "\t step:300/662, average time: 0.9021, loss: 0.282961 Batch Acc:0.920898438, Acc:0.920898438\r\n",
      "\t step:320/662, average time: 0.8901, loss: 0.254603 Batch Acc:0.920898438, Acc:0.922665551\r\n",
      "\t step:340/662, average time: 0.8793, loss: 0.256955 Batch Acc:0.920898438, Acc:0.924066311\r\n",
      "\t step:360/662, average time: 0.8698, loss: 0.232090 Batch Acc:0.926757812, Acc:0.925445056\r\n",
      "\t step:380/662, average time: 0.8613, loss: 0.256064 Batch Acc:0.920898438, Acc:0.925431617\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:20<00:00,  3.68it/s]\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss: 0.20382, accu: 0.9363837\r\n",
      "\t step:400/662, average time: 0.9026, loss: 0.232496 Batch Acc:0.927734375, Acc:0.927734375\r\n",
      "\t step:420/662, average time: 0.8933, loss: 0.221265 Batch Acc:0.931640625, Acc:0.930013021\r\n"
     ]
    }
   ],
   "source": [
    "# 定义优化器、损失函数和Acc计算器\n",
    "optimizer = paddle.optimizer.Adam(learning_rate=LEARNING_RATE,\n",
    "                            parameters=model.parameters(),\n",
    "                            )\n",
    "criterion = paddle.nn.loss.CrossEntropyLoss()\n",
    "metric = paddle.metric.Accuracy()\n",
    "\n",
    "# 调整至训练模式\n",
    "model.train() \n",
    "best_acc = 0.94\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"epoch: {epoch + 1}, {time.ctime()}\")\n",
    "    start_t = time.time()\n",
    "    metric.reset()\n",
    "    for ind, item in enumerate(train_data_loader()):\n",
    "        if ind and (not ind%SAVE_FREQUENCE):\n",
    "            accu = evaluate(model, criterion, metric, val_data_loader)\n",
    "            if accu > best_acc:\n",
    "                best_acc = accu\n",
    "                print('\\t Best Acc: {:.6f}'.format(accu))\n",
    "                model.save_pretrained(SAVE_PATH)\n",
    "                tokenizer.save_pretrained(SAVE_PATH)\n",
    "        input_ids, token_type_ids, labels = item\n",
    "        logits = model(input_ids, token_type_ids)\n",
    "        loss = criterion(logits, labels)\n",
    "        probs = F.softmax(logits, axis=1)\n",
    "\n",
    "        correct = metric.compute(probs, labels)\n",
    "        batch_acc = metric.update(correct)\n",
    "        acc = metric.accumulate()\n",
    "        \n",
    "        loss.backward()\n",
    "        ave_t = (time.time() - start_t)/(ind + 1)\n",
    "        extra_h = ave_t*(len(train_data_loader) - ind + 1)/3600\n",
    "        if ind and (not ind%LOG_FREQUENCE):\n",
    "            print(f'\\t step:{ind}/{len(train_data_loader)},', 'average time: {:.4f},'.format(ave_t), 'loss: {:.6f}'.format(loss.numpy()[0]), 'Batch Acc:{:.9f}, Acc:{:.9f}'.format(batch_acc, acc))\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.clear_grad()\n",
    "        # scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a0ed94-435e-4b32-9ace-7c36b7ab9b8e",
   "metadata": {},
   "source": [
    "## 加载和推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3afd83-a351-49bf-9692-761aab771f9d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_dict = paddle.load(os.path.join(SAVE_PATH, 'model_state.pdparams'))\n",
    "inf_model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_classes=14)\n",
    "inf_model.set_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd908a8-177c-4405-a40f-27c3f06b9288",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 使用前先再次评估\n",
    "ev_acc = evaluate(inf_model, criterion, metric, val_data_loader)\n",
    "with open('./record.txt', 'w+') as f:\n",
    "    f.write(MODEL_NAME + '\\t' + str(ev_acc) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b26095f-84cd-4e1c-9510-e55b8b59a515",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "inf_model.eval()\n",
    "res = []\n",
    "for input_ids, token_type_ids in tqdm(test_data_loader):\n",
    "    logits = inf_model(input_ids, token_type_ids)\n",
    "    curr_ind = paddle.argmax(logits, axis=1)\n",
    "    res += curr_ind.numpy().tolist()\n",
    "\n",
    "for input_ids, token_type_ids in tqdm(test_dataset_part2):\n",
    "    input_ids, token_type_ids = paddle.to_tensor(input_ids.reshape(1, 48) , dtype='int64'), paddle.to_tensor(token_type_ids.reshape(1, 48) , dtype='int64')\n",
    "    logits = inf_model(input_ids, token_type_ids)\n",
    "    curr_ind = paddle.argmax(logits, axis=1)\n",
    "    res += curr_ind.numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d4818b-5535-44d1-928d-159cad762f27",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%rm -rf ./result.txt\n",
    "class_lis = ['财经', '彩票', '房产', '股票', '家居', '教育', '科技', '社会', '时尚', '时政', '体育', '星座', '游戏', '娱乐']\n",
    "label_dict = {ind: content for ind, content in enumerate(class_lis)}\n",
    "assert len(res) == 83599, '最终输出的list长度不正确，需要检查test_data是否合理划分'\n",
    "with open('./result.txt', 'w') as f:\n",
    "    print('推理样例：')\n",
    "    for i in range(83599):\n",
    "        # text = label_dict[res[i]] + '\\t' + test_data.iloc[i]['title'] + '\\n'\n",
    "        text = label_dict[res[i]] + '\\n'\n",
    "        if not i%100:\n",
    "            print('\\t', label_dict[res[i]] + '\\t' + test_data.iloc[i]['title'])\n",
    "        f.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e76efc-71c1-4bb6-b047-3a68f30a9dea",
   "metadata": {},
   "source": [
    "## 最终分数 88.2分"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
